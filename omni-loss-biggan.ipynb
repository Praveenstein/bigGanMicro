{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:48.623112Z",
     "iopub.status.busy": "2021-05-12T05:40:48.621513Z",
     "iopub.status.idle": "2021-05-12T05:40:51.352905Z",
     "shell.execute_reply": "2021-05-12T05:40:51.352242Z"
    },
    "papermill": {
     "duration": 2.755864,
     "end_time": "2021-05-12T05:40:51.353059",
     "exception": false,
     "start_time": "2021-05-12T05:40:48.597195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torchvision.utils import make_grid\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#from torchsummaryX import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:51.394016Z",
     "iopub.status.busy": "2021-05-12T05:40:51.393457Z",
     "iopub.status.idle": "2021-05-12T05:40:59.288763Z",
     "shell.execute_reply": "2021-05-12T05:40:59.288233Z"
    },
    "papermill": {
     "duration": 7.917559,
     "end_time": "2021-05-12T05:40:59.288929",
     "exception": false,
     "start_time": "2021-05-12T05:40:51.371370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\r\n",
      "  Downloading openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 243 kB 1.2 MB/s \r\n",
      "\u001b[?25hCollecting et-xmlfile\r\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020651,
     "end_time": "2021-05-12T05:40:59.330619",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.309968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Class Conditional Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.384025Z",
     "iopub.status.busy": "2021-05-12T05:40:59.383273Z",
     "iopub.status.idle": "2021-05-12T05:40:59.386077Z",
     "shell.execute_reply": "2021-05-12T05:40:59.385647Z"
    },
    "papermill": {
     "duration": 0.033907,
     "end_time": "2021-05-12T05:40:59.386189",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.352282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ClassConditionalBN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, eps=1e-4, momentum=0.1):\n",
    "        super(ClassConditionalBN, self).__init__()\n",
    "        self.output_size, self.input_size = output_size, input_size\n",
    "        # Prepare gain and bias layers\n",
    "        self.gain = spectral_norm(nn.Linear(input_size, output_size, bias = False), eps = 1e-4)\n",
    "        self.bias = spectral_norm(nn.Linear(input_size, output_size, bias = False), eps = 1e-4)\n",
    "        # epsilon to avoid dividing by 0\n",
    "        self.eps = eps\n",
    "        # Momentum\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.register_buffer('stored_mean', torch.zeros(output_size))\n",
    "        self.register_buffer('stored_var',  torch.ones(output_size))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # Calculate class-conditional gains and biases\n",
    "        gain = (1 + self.gain(y)).view(y.size(0), -1, 1, 1)\n",
    "        bias = self.bias(y).view(y.size(0), -1, 1, 1)\n",
    "        out = F.batch_norm(x, self.stored_mean, self.stored_var, None, None,\n",
    "                          self.training, 0.1, self.eps)\n",
    "        return out * gain + bias\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        s = 'out: {output_size}, in: {input_size},'\n",
    "        return s.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020582,
     "end_time": "2021-05-12T05:40:59.427620",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.407038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Self Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.480572Z",
     "iopub.status.busy": "2021-05-12T05:40:59.479671Z",
     "iopub.status.idle": "2021-05-12T05:40:59.481743Z",
     "shell.execute_reply": "2021-05-12T05:40:59.482227Z"
    },
    "papermill": {
     "duration": 0.033732,
     "end_time": "2021-05-12T05:40:59.482365",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.448633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self,in_dim,activation = nn.ReLU(inplace = False)):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020504,
     "end_time": "2021-05-12T05:40:59.523763",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.503259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generator Resblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.580342Z",
     "iopub.status.busy": "2021-05-12T05:40:59.579379Z",
     "iopub.status.idle": "2021-05-12T05:40:59.582130Z",
     "shell.execute_reply": "2021-05-12T05:40:59.581725Z"
    },
    "papermill": {
     "duration": 0.037638,
     "end_time": "2021-05-12T05:40:59.582245",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.544607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GeneratorResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, upsample = None, embed_dim = 128, dim_z = 384):\n",
    "        super(GeneratorResBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.hidden_channels = self.in_channels // 4\n",
    "        \n",
    "        self.conv1 = spectral_norm(nn.Conv2d(self.in_channels, self.hidden_channels, kernel_size = 1, padding = 0), eps = 1e-4)\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(self.hidden_channels, self.hidden_channels, kernel_size = 3, padding = 1), eps = 1e-4)\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(self.hidden_channels, self.hidden_channels, kernel_size = 3, padding = 1), eps = 1e-4)\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(self.hidden_channels, self.out_channels, kernel_size = 1, padding = 0), eps = 1e-4)\n",
    "        \n",
    "        self.bn1 = ClassConditionalBN((3 * embed_dim) + dim_z, self.in_channels)\n",
    "        self.bn2 = ClassConditionalBN((3 * embed_dim) + dim_z, self.hidden_channels)\n",
    "        self.bn3 = ClassConditionalBN((3 * embed_dim) + dim_z, self.hidden_channels)\n",
    "        self.bn4 = ClassConditionalBN((3 * embed_dim) + dim_z, self.hidden_channels)\n",
    "        \n",
    "        self.activation = nn.ReLU(inplace=False)\n",
    "        \n",
    "        self.upsample = upsample\n",
    "        \n",
    "    def forward(self,x,y):\n",
    "        # Project down to channel ratio\n",
    "        h = self.conv1(self.activation(self.bn1(x, y)))\n",
    "        # Apply next BN-ReLU\n",
    "        h = self.activation(self.bn2(h, y))\n",
    "        # Drop channels in x if necessary\n",
    "        if self.in_channels != self.out_channels:\n",
    "            x = x[:, :self.out_channels]      \n",
    "        # Upsample both h and x at this point  \n",
    "        if self.upsample:\n",
    "            h = self.upsample(h)\n",
    "            x = self.upsample(x)\n",
    "        # 3x3 convs\n",
    "        h = self.conv2(h)\n",
    "        h = self.conv3(self.activation(self.bn3(h, y)))\n",
    "        # Final 1x1 conv\n",
    "        h = self.conv4(self.activation(self.bn4(h, y)))\n",
    "        return h + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021846,
     "end_time": "2021-05-12T05:40:59.625610",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.603764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BigGAN-deep Generator \n",
    "This version of the generator has a different input mechanism from that of the original version in the paper. This change was made to accomodate multiple conditional inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.691305Z",
     "iopub.status.busy": "2021-05-12T05:40:59.690418Z",
     "iopub.status.idle": "2021-05-12T05:40:59.692668Z",
     "shell.execute_reply": "2021-05-12T05:40:59.693070Z"
    },
    "papermill": {
     "duration": 0.04512,
     "end_time": "2021-05-12T05:40:59.693211",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.648091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, G_ch = 64, dim_z = 384, bottom_width=4, img_channels = 1,\n",
    "                 init = 'N02',n_classes_temp = 7, n_classes_time = 8, n_classes_cool = 4, embed_dim = 128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ch = G_ch\n",
    "        self.dim_z = dim_z\n",
    "        self.bottom_width = bottom_width\n",
    "        self.init = init\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        self.embed_temp = nn.Embedding(n_classes_temp, embed_dim)\n",
    "        self.embed_time = nn.Embedding(n_classes_time, embed_dim)\n",
    "        self.embed_cool = nn.Embedding(n_classes_cool, embed_dim)\n",
    "        \n",
    "        self.linear = spectral_norm(nn.Linear(dim_z + (3 * embed_dim), 16 * self.ch * (self.bottom_width **2)), eps = 1e-4)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "                GeneratorResBlock(16*self.ch, 16*self.ch),\n",
    "                GeneratorResBlock(16*self.ch, 16*self.ch, upsample =  nn.Upsample(scale_factor = 2)),\n",
    "                GeneratorResBlock(16*self.ch, 16*self.ch),\n",
    "                GeneratorResBlock(16*self.ch, 8*self.ch, upsample =  nn.Upsample(scale_factor = 2)),\n",
    "                GeneratorResBlock(8*self.ch, 8*self.ch),\n",
    "                GeneratorResBlock(8*self.ch, 8*self.ch, upsample =  nn.Upsample(scale_factor = 2)),\n",
    "                GeneratorResBlock(8*self.ch, 8*self.ch),\n",
    "                GeneratorResBlock(8*self.ch, 4*self.ch, upsample =  nn.Upsample(scale_factor = 2)),\n",
    "                Self_Attn(4*self.ch),\n",
    "                GeneratorResBlock(4*self.ch, 4*self.ch),\n",
    "                GeneratorResBlock(4*self.ch, 2*self.ch, upsample =  nn.Upsample(scale_factor = 2)),\n",
    "                GeneratorResBlock(2*self.ch, 2*self.ch),\n",
    "                GeneratorResBlock(2*self.ch,  self.ch, upsample =  nn.Upsample(scale_factor = 2))\n",
    "        ])\n",
    "        \n",
    "        self.final_layer = nn.Sequential(\n",
    "                nn.BatchNorm2d(self.ch),\n",
    "                nn.ReLU(inplace = False),\n",
    "                spectral_norm(nn.Conv2d(self.ch, self.img_channels, kernel_size = 3, padding = 1)),\n",
    "                nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.init_weights()\n",
    "                                    \n",
    "    def init_weights(self):\n",
    "        print(f\"Weight initialization : {self.init}\")\n",
    "        self.param_count = 0\n",
    "        for module in self.modules():\n",
    "            if (isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, nn.Embedding)):\n",
    "                if self.init == 'ortho':\n",
    "                    torch.nn.init.orthogonal_(module.weight)\n",
    "                elif self.init == 'N02':\n",
    "                    torch.nn.init.normal_(module.weight, 0, 0.02)\n",
    "                elif self.init in ['glorot', 'xavier']:\n",
    "                    torch.nn.init.xavier_uniform_(module.weight)\n",
    "                else:\n",
    "                    print('Init style not recognized...')\n",
    "                self.param_count += sum([p.data.nelement() for p in module.parameters()])\n",
    "        print(\"Param count for G's initialized parameters: %d Million\" % (self.param_count/1000000))\n",
    "        \n",
    "        \n",
    "    def forward(self,z , y_temp, y_time, y_cool):\n",
    "        y_temp = self.embed_temp(y_temp)\n",
    "        y_time = self.embed_time(y_time)\n",
    "        y_cool = self.embed_cool(y_cool)\n",
    "        z = torch.cat([z, y_temp, y_time, y_cool], 1)     \n",
    "        # First linear layer\n",
    "        h = self.linear(z)\n",
    "        # Reshape\n",
    "        h = h.view(h.size(0), -1, self.bottom_width, self.bottom_width)    \n",
    "        # Loop over blocks\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i != 8:\n",
    "                h = block(h, z)\n",
    "            else:\n",
    "                h = block(h)\n",
    "        # Apply batchnorm-relu-conv-tanh at output\n",
    "        h = self.final_layer(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021752,
     "end_time": "2021-05-12T05:40:59.737083",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.715331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Discriminator Resblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.792117Z",
     "iopub.status.busy": "2021-05-12T05:40:59.791327Z",
     "iopub.status.idle": "2021-05-12T05:40:59.794226Z",
     "shell.execute_reply": "2021-05-12T05:40:59.793762Z"
    },
    "papermill": {
     "duration": 0.036436,
     "end_time": "2021-05-12T05:40:59.794341",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.757905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiscriminatorResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, preactivation=True, \n",
    "                 downsample=None,channel_ratio=4):\n",
    "        super(DiscriminatorResBlock, self).__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        # If using wide D (as in SA-GAN and BigGAN), change the channel pattern\n",
    "        self.hidden_channels = self.out_channels // channel_ratio\n",
    "        self.preactivation = preactivation\n",
    "        self.activation = nn.ReLU(inplace=False)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "        # Conv layers\n",
    "        self.conv1 = spectral_norm(nn.Conv2d(self.in_channels, self.hidden_channels, \n",
    "                                 kernel_size=1, padding=0), eps = 1e-4)\n",
    "        self.conv2 = spectral_norm(nn.Conv2d(self.hidden_channels, self.hidden_channels, kernel_size = 3, padding = 1), eps = 1e-4)\n",
    "        self.conv3 = spectral_norm(nn.Conv2d(self.hidden_channels, self.hidden_channels, kernel_size = 3, padding = 1), eps = 1e-4)\n",
    "        self.conv4 = spectral_norm(nn.Conv2d(self.hidden_channels, self.out_channels, \n",
    "                                 kernel_size=1, padding=0), eps = 1e-4)\n",
    "                                 \n",
    "        self.learnable_sc = True if (in_channels != out_channels) else False\n",
    "        if self.learnable_sc:\n",
    "            self.conv_sc = spectral_norm(nn.Conv2d(in_channels, out_channels - in_channels, \n",
    "                                     kernel_size=1, padding=0), eps = 1e-4)\n",
    "            \n",
    "    def shortcut(self, x):\n",
    "        if self.downsample:\n",
    "            x = self.downsample(x)\n",
    "        if self.learnable_sc:\n",
    "            x = torch.cat([x, self.conv_sc(x)], 1)    \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 1x1 bottleneck conv\n",
    "        h = self.conv1(F.relu(x))\n",
    "        # 3x3 convs\n",
    "        h = self.conv2(self.activation(h))\n",
    "        h = self.conv3(self.activation(h))\n",
    "        # relu before downsample\n",
    "        h = self.activation(h)\n",
    "        # downsample\n",
    "        if self.downsample:\n",
    "            h = self.downsample(h)     \n",
    "        # final 1x1 conv\n",
    "        h = self.conv4(h)\n",
    "        return h + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020773,
     "end_time": "2021-05-12T05:40:59.836086",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.815313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## BigGAN-deep Discriminator\n",
    "The discriminator is modified to output a 21 dimensional vector and no class conditional information is provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:40:59.892421Z",
     "iopub.status.busy": "2021-05-12T05:40:59.891385Z",
     "iopub.status.idle": "2021-05-12T05:40:59.896694Z",
     "shell.execute_reply": "2021-05-12T05:40:59.896271Z"
    },
    "papermill": {
     "duration": 0.039824,
     "end_time": "2021-05-12T05:40:59.896806",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.856982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, D_ch = 64, img_channels = 1, init = 'N02', n_classes_temp = 7, n_classes_time = 8, n_classes_cool = 4):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ch = D_ch\n",
    "        self.init = init\n",
    "        self.img_channels = img_channels\n",
    "        self.output_dim = n_classes_temp + n_classes_time + n_classes_cool + 2\n",
    "        \n",
    "        # Prepare model\n",
    "        # Stem convolution\n",
    "        self.input_conv = spectral_norm(nn.Conv2d(self.img_channels, self.ch, kernel_size = 3, padding = 1), eps = 1e-4)\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "                DiscriminatorResBlock(self.ch, 2*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(2*self.ch, 2*self.ch),\n",
    "                DiscriminatorResBlock(2*self.ch, 4*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(4*self.ch, 4*self.ch),\n",
    "                Self_Attn(4*self.ch),\n",
    "                DiscriminatorResBlock(4*self.ch, 8*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(8*self.ch, 8*self.ch),\n",
    "                DiscriminatorResBlock(8*self.ch, 8*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(8*self.ch, 8*self.ch),\n",
    "                DiscriminatorResBlock(8*self.ch, 16*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(16*self.ch, 16*self.ch),\n",
    "                DiscriminatorResBlock(16*self.ch, 16*self.ch, downsample = nn.AvgPool2d(2)),\n",
    "                DiscriminatorResBlock(16*self.ch, 16*self.ch),\n",
    "        )\n",
    "        # Linear output layer. The output dimension is typically 1, but may be\n",
    "        # larger if we're e.g. turning this into a VAE with an inference output\n",
    "        self.linear = spectral_norm(nn.Linear(16*self.ch, self.output_dim), eps = 1e-4)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        print(f\"Weight initialization : {self.init}\")\n",
    "        self.param_count = 0\n",
    "        for module in self.modules():\n",
    "            if (isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear) or isinstance(module, nn.Embedding)):\n",
    "                if self.init == 'ortho':\n",
    "                    torch.nn.init.orthogonal_(module.weight)\n",
    "                elif self.init == 'N02':\n",
    "                    torch.nn.init.normal_(module.weight, 0, 0.02)\n",
    "                elif self.init in ['glorot', 'xavier']:\n",
    "                    torch.nn.init.xavier_uniform_(module.weight)\n",
    "                else:\n",
    "                    print('Init style not recognized...')\n",
    "                self.param_count += sum([p.data.nelement() for p in module.parameters()])\n",
    "        print(\"Param count for D's initialized parameters: %d Million\" % (self.param_count/1000000))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Run input conv\n",
    "        h = self.input_conv(x)\n",
    "        # Blocks\n",
    "        h = self.blocks(h)\n",
    "        # Apply global sum pooling as in SN-GAN\n",
    "        h = torch.sum(nn.ReLU(inplace = False)(h), [2, 3])\n",
    "        # Get initial class-unconditional output\n",
    "        out = self.linear(h)\n",
    "        # Get projection of final featureset onto class vectors and add to evidence\n",
    "        #out = out + torch.sum(self.embed_temp(y_temp) * h, 1, keepdim=True) + torch.sum(self.embed_time(y_time) * h, 1, keepdim=True) + torch.sum(self.embed_cool(y_cool) * h, 1, keepdim=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020852,
     "end_time": "2021-05-12T05:40:59.938450",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.917598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Differentiable Augmentation for GAN\n",
    "The implementation follows the Color-Translation-Cutout policy from this [paper](https://arxiv.org/pdf/2006.10738.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.003553Z",
     "iopub.status.busy": "2021-05-12T05:41:00.002673Z",
     "iopub.status.idle": "2021-05-12T05:41:00.005189Z",
     "shell.execute_reply": "2021-05-12T05:41:00.004788Z"
    },
    "papermill": {
     "duration": 0.045901,
     "end_time": "2021-05-12T05:41:00.005300",
     "exception": false,
     "start_time": "2021-05-12T05:40:59.959399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiffAugment:\n",
    "    def __init__(self, policy='color,translation,cutout', channels_first=True):\n",
    "        self.policy = policy\n",
    "        print(f'Diff. Augment Policy : {policy}')\n",
    "        self.channels_first = channels_first\n",
    "        self.AUGMENT_FNS = {'color': [self.rand_brightness, self.rand_saturation, self.rand_contrast],\n",
    "                            'translation': [self.rand_translation],\n",
    "                            'cutout': [self.rand_cutout]}\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if self.policy:\n",
    "            if not self.channels_first:\n",
    "                x = x.permute(0, 3, 1, 2)\n",
    "            for p in self.policy.split(','):\n",
    "                for f in self.AUGMENT_FNS[p]:\n",
    "                    x = f(x)\n",
    "            if not self.channels_first:\n",
    "                x = x.permute(0, 2, 3, 1)\n",
    "            x = x.contiguous()\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def rand_brightness(self, x):\n",
    "        x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
    "        return x\n",
    "    \n",
    "    def rand_saturation(self, x):\n",
    "        x_mean = x.mean(dim=1, keepdim=True)\n",
    "        x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
    "        return x\n",
    "    \n",
    "    def rand_contrast(self,x):\n",
    "        x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
    "        x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
    "        return x\n",
    "    \n",
    "    def rand_translation(self, x, ratio = 0.125):\n",
    "        shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "        translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "        translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
    "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "            torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
    "            torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
    "        )\n",
    "        grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
    "        grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
    "        x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
    "        x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
    "        return x\n",
    "    \n",
    "    def rand_cutout(self, x, ratio=0.5):\n",
    "        cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
    "        offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "        offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
    "        grid_batch, grid_x, grid_y = torch.meshgrid(\n",
    "            torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
    "            torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
    "            torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
    "        )\n",
    "        grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
    "        grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
    "        mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
    "        mask[grid_batch, grid_x, grid_y] = 0\n",
    "        x = x * mask.unsqueeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020992,
     "end_time": "2021-05-12T05:41:00.047398",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.026406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom sampler to balance the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.099675Z",
     "iopub.status.busy": "2021-05-12T05:41:00.098826Z",
     "iopub.status.idle": "2021-05-12T05:41:00.101540Z",
     "shell.execute_reply": "2021-05-12T05:41:00.101057Z"
    },
    "papermill": {
     "duration": 0.033026,
     "end_time": "2021-05-12T05:41:00.101649",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.068623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImbalancedDatasetSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly from a given list of indices for imbalanced dataset\n",
    "    Arguments:\n",
    "        indices (list, optional): a list of indices\n",
    "        num_samples (int, optional): number of samples to draw\n",
    "        callback_get_label func: a callback-like function which takes two arguments - dataset and index\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices=None, num_samples=None, callback_get_label=None):\n",
    "                \n",
    "        # if indices is not provided, \n",
    "        # all elements in the dataset will be considered\n",
    "        self.indices = list(range(len(dataset))) \\\n",
    "            if indices is None else indices\n",
    "        \n",
    "        # define custom callback\n",
    "        self.callback_get_label = callback_get_label\n",
    "        \n",
    "        # if num_samples is not provided, \n",
    "        # draw `len(indices)` samples in each iteration\n",
    "        self.num_samples = len(self.indices) \\\n",
    "            if num_samples is None else num_samples\n",
    "            \n",
    "        # distribution of classes in the dataset for temp , time and cool \n",
    "        label_to_count = {}\n",
    "        for idx in self.indices:\n",
    "            label = self._get_label(dataset, idx)\n",
    "            if label in label_to_count:\n",
    "                label_to_count[label] += 1\n",
    "            else:\n",
    "                label_to_count[label] = 1\n",
    "                \n",
    "        # weight for each sample\n",
    "        weights = [1.0 / label_to_count[self._get_label(dataset, idx)]\n",
    "                   for idx in self.indices]\n",
    "        weights = torch.DoubleTensor(weights)\n",
    "        self.weights= weights\n",
    "    \n",
    "    def _get_label(self, dataset, idx):\n",
    "        return dataset[idx][4]\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return (self.indices[i] for i in torch.multinomial(\n",
    "            self.weights, self.num_samples, replacement=True))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.021281,
     "end_time": "2021-05-12T05:41:00.143963",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.122682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom dataset for UHCSDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.197546Z",
     "iopub.status.busy": "2021-05-12T05:41:00.196765Z",
     "iopub.status.idle": "2021-05-12T05:41:00.199550Z",
     "shell.execute_reply": "2021-05-12T05:41:00.199131Z"
    },
    "papermill": {
     "duration": 0.034447,
     "end_time": "2021-05-12T05:41:00.199666",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.165219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MicrographDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom Dataset class for Micrograph data which returns the following\n",
    "    # Micrograph image\n",
    "    # Inputs : Anneal Temperature , Anneal Time and Type of cooling used\n",
    "    ------------------------------------------------------------------------------------\n",
    "    Attributes\n",
    "    \n",
    "    df : pandas.core.frame.DataFrame\n",
    "        A Dataframe that contains the proper entries (i.e. dataframe corresponding to new_metadata.xlsx)\n",
    "    root_dir : str\n",
    "        The path of the folder where the images are located\n",
    "    transform : torchvision.transforms.transforms.Compose\n",
    "        The transforms that are to be applied to the loaded images\n",
    "    \"\"\"\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        temp_dict = {970: 0, 800: 1, 900: 2, 1100: 3, 1000: 4, 700: 5, 750: 6}\n",
    "        time_dict = {90: 0, 1440: 1, 180: 2, 5: 3, 480: 4, 5100: 5, 60: 6, 2880: 7}\n",
    "        microconst_dict = {'spheroidite': 0, 'network' : 1,'spheroidite+widmanstatten' : 2, 'pearlite+spheroidite' : 3,\n",
    "                         'pearlite' : 4,'pearlite+widmanstatten' : 5}\n",
    "        cooling_dict = {'Q': 0, 'FC': 1, 'AR': 2, '650-1H': 3}\n",
    "        row = self.df.loc[idx]\n",
    "        img_name = row['path']\n",
    "        img_path = self.root_dir + '/' + 'Cropped' + img_name\n",
    "        anneal_temp = temp_dict[row['anneal_temperature']]\n",
    "        if row['anneal_time_unit'] == 'H':\n",
    "            anneal_time = int(row['anneal_time']) * 60\n",
    "        else:\n",
    "            anneal_time = row['anneal_time']\n",
    "        anneal_time = time_dict[anneal_time]\n",
    "        cooling_type = cooling_dict[row['cool_method']]\n",
    "        microconst = microconst_dict[row['primary_microconstituent']]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img , anneal_temp, anneal_time, cooling_type, microconst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022176,
     "end_time": "2021-05-12T05:41:00.244556",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.222380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Lightining Module for GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.291050Z",
     "iopub.status.busy": "2021-05-12T05:41:00.290171Z",
     "iopub.status.idle": "2021-05-12T05:41:00.320279Z",
     "shell.execute_reply": "2021-05-12T05:41:00.319873Z"
    },
    "papermill": {
     "duration": 0.054443,
     "end_time": "2021-05-12T05:41:00.320388",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.265945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MicrographBigGAN(pl.LightningModule):\n",
    "    def __init__(self, root_dir, df_dir, batch_size, augment_bool = True, lr = 0.0002,\n",
    "                 n_classes_temp = 7, n_classes_time = 8, n_classes_cool = 4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.root_dir = root_dir\n",
    "        self.df_dir = df_dir\n",
    "        self.generator = Generator(G_ch = 64)\n",
    "        self.discriminator = Discriminator(D_ch = 64)\n",
    "        self.diffaugment = DiffAugment()\n",
    "        self.augment_bool = augment_bool\n",
    "        self.batch_size = batch_size \n",
    "        self.lr = lr\n",
    "        self.n_classes_temp = n_classes_temp\n",
    "        self.n_classes_time = n_classes_time\n",
    "        self.n_classes_cool = n_classes_cool\n",
    "        \n",
    "    def forward(self, z, y_temp, y_time, y_cool):\n",
    "        return self.generator(z, y_temp, y_time, y_cool)\n",
    "    \n",
    "    def multilabel_categorical_crossentropy(self, y_true, y_pred, margin=0., gamma=1.):\n",
    "        \"\"\" y_true: positive=1, negative=0, ignore=-1\n",
    "        \"\"\"\n",
    "        y_true = y_true.clamp(-1, 1)\n",
    "        if len(y_pred.shape) > 2:\n",
    "            y_true = y_true.view(y_true.shape[0], 1, 1, -1)\n",
    "            _, _, h, w = y_pred.shape\n",
    "            y_true = y_true.expand(-1, h, w, -1)\n",
    "            y_pred = y_pred.permute(0, 2, 3, 1)\n",
    "\n",
    "        y_pred = y_pred + margin\n",
    "        y_pred = y_pred * gamma\n",
    "\n",
    "        y_pred[y_true == 1] = -1 * y_pred[y_true == 1]\n",
    "        y_pred[y_true == -1] = -1e12\n",
    "\n",
    "        y_pred_neg = y_pred.clone()\n",
    "        y_pred_neg[y_true == 1] = -1e12\n",
    "\n",
    "        y_pred_pos = y_pred.clone()\n",
    "        y_pred_pos[y_true == 0] = -1e12\n",
    "\n",
    "        zeros = torch.zeros_like(y_pred[..., :1])\n",
    "        y_pred_neg = torch.cat([y_pred_neg, zeros], dim=-1)\n",
    "        y_pred_pos = torch.cat([y_pred_pos, zeros], dim=-1)\n",
    "        neg_loss = torch.logsumexp(y_pred_neg, dim=-1)\n",
    "        pos_loss = torch.logsumexp(y_pred_pos, dim=-1)\n",
    "        return neg_loss + pos_loss\n",
    "    \n",
    "    def Omni_Dloss(self,disc_real, disc_fake, y_temp_real, y_time_real, y_cool_real):\n",
    "        b = y_temp_real.shape[0]\n",
    "        y_temp = F.one_hot(y_temp_real, num_classes = self.n_classes_temp).to(self.device)\n",
    "        y_time = F.one_hot(y_time_real, num_classes = self.n_classes_time).to(self.device)\n",
    "        y_cool = F.one_hot(y_cool_real, num_classes = self.n_classes_cool).to(self.device)\n",
    "        y_real = torch.cat([y_temp,y_time,y_cool,torch.tensor([1,0]).repeat(b,1).to(self.device)],1).float()\n",
    "        y_real.requires_grad = True\n",
    "        y_fake = torch.cat([torch.zeros((b, self.n_classes_temp + self.n_classes_time + self.n_classes_cool)),torch.tensor([0,1]).repeat(b,1)],1).float().to(self.device)\n",
    "        y_fake.requires_grad = True\n",
    "        d_loss_real = self.multilabel_categorical_crossentropy(y_true = y_real, y_pred = disc_real)\n",
    "        d_loss_fake = self.multilabel_categorical_crossentropy(y_true = y_fake, y_pred = disc_fake)\n",
    "        d_loss = d_loss_real.mean() + d_loss_fake.mean()\n",
    "        return d_loss\n",
    "    \n",
    "    def Omni_Gloss(self, disc_fake, y_temp_fake, y_time_fake, y_cool_fake):\n",
    "        b = y_temp_fake.shape[0]\n",
    "        y_temp = F.one_hot(y_temp_fake, num_classes = self.n_classes_temp).to(self.device)\n",
    "        y_time = F.one_hot(y_time_fake, num_classes = self.n_classes_time).to(self.device)\n",
    "        y_cool = F.one_hot(y_cool_fake, num_classes = self.n_classes_cool).to(self.device)\n",
    "        y_fake_g = torch.cat([y_temp,y_time,y_cool,torch.tensor([1,0]).repeat(b,1).to(self.device)],1).float()\n",
    "        y_fake_g.requires_grad = True\n",
    "        g_loss = self.multilabel_categorical_crossentropy(y_true = y_fake_g, y_pred = disc_fake)\n",
    "        return g_loss.mean()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real, y_temp_real, y_time_real, y_cool_real , _ = batch\n",
    "        z = torch.randn(real.shape[0], 384)\n",
    "        z = z.type_as(real)\n",
    "        y_temp_fake = torch.randint(self.n_classes_temp,(real.shape[0],)).to(self.device)\n",
    "        y_time_fake = torch.randint(self.n_classes_time,(real.shape[0],)).to(self.device)\n",
    "        y_cool_fake = torch.randint(self.n_classes_cool,(real.shape[0],)).to(self.device)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            fake = self(z, y_temp_fake, y_time_fake, y_cool_fake)\n",
    "            \n",
    "            if self.augment_bool:\n",
    "                disc_real = self.discriminator(self.diffaugment(real))\n",
    "                disc_fake = self.discriminator(self.diffaugment(fake))\n",
    "            else:\n",
    "                disc_real = self.discriminator(real)\n",
    "                disc_fake = self.discriminator(fake)\n",
    "            d_loss = self.Omni_Dloss(disc_real, disc_fake, y_temp_real, y_time_real, y_cool_real)\n",
    "            #print(d_loss.requires_grad)\n",
    "            tqdm_dict = {'d_loss': d_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': d_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "                })\n",
    "            return output\n",
    "        \n",
    "        if optimizer_idx == 1:\n",
    "            fake = self(z,y_temp_fake, y_time_fake, y_cool_fake)\n",
    "            if self.augment_bool:\n",
    "                disc_fake = self.discriminator(self.diffaugment(fake))\n",
    "            else:\n",
    "                disc_fake = self.discriminator(fake)\n",
    "            g_loss = self.Omni_Gloss(disc_fake, y_temp_fake, y_time_fake, y_cool_fake)\n",
    "            #print(g_loss.requires_grad)\n",
    "            tqdm_dict = {'g_loss': g_loss}\n",
    "            output = OrderedDict({\n",
    "                'loss': g_loss,\n",
    "                'progress_bar': tqdm_dict,\n",
    "                'log': tqdm_dict\n",
    "            })\n",
    "            return output\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        opt_g = optim.Adam(self.generator.parameters(), lr = self.lr, weight_decay = 0.001)\n",
    "        opt_d = optim.Adam(self.discriminator.parameters(), lr = self.lr, weight_decay = 0.0005)\n",
    "        return (\n",
    "            {'optimizer': opt_d, 'frequency': 4},\n",
    "            {'optimizer': opt_g, 'frequency': 1}\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        img_transforms = transforms.Compose([\n",
    "            transforms.RandomCrop(256),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.Resize([256, 256]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5 for _ in range(1)],[0.5 for _ in range(1)]),\n",
    "        ])\n",
    "        df = pd.read_excel(self.df_dir,engine = 'openpyxl')\n",
    "        dataset = MicrographDataset(df,self.root_dir,transform = img_transforms)\n",
    "        return DataLoader(dataset, sampler = ImbalancedDatasetSampler(dataset), \n",
    "                          batch_size=self.batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.367953Z",
     "iopub.status.busy": "2021-05-12T05:41:00.367205Z",
     "iopub.status.idle": "2021-05-12T05:41:00.369515Z",
     "shell.execute_reply": "2021-05-12T05:41:00.369901Z"
    },
    "papermill": {
     "duration": 0.027684,
     "end_time": "2021-05-12T05:41:00.370032",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.342348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = '../input/highcarbon-micrographs/For Training/Cropped'\n",
    "DF_DIR = '../input/highcarbon-micrographs/new_metadata.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:00.417973Z",
     "iopub.status.busy": "2021-05-12T05:41:00.417450Z",
     "iopub.status.idle": "2021-05-12T05:41:01.386394Z",
     "shell.execute_reply": "2021-05-12T05:41:01.386953Z"
    },
    "papermill": {
     "duration": 0.995368,
     "end_time": "2021-05-12T05:41:01.387148",
     "exception": false,
     "start_time": "2021-05-12T05:41:00.391780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight initialization : N02\n",
      "Param count for G's initialized parameters: 39 Million\n",
      "Weight initialization : N02\n",
      "Param count for D's initialized parameters: 9 Million\n",
      "Diff. Augment Policy : color,translation,cutout\n"
     ]
    }
   ],
   "source": [
    "gan = MicrographBigGAN(ROOT_DIR,DF_DIR,batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:01.507288Z",
     "iopub.status.busy": "2021-05-12T05:41:01.506408Z",
     "iopub.status.idle": "2021-05-12T05:41:01.510356Z",
     "shell.execute_reply": "2021-05-12T05:41:01.510902Z"
    },
    "papermill": {
     "duration": 0.100204,
     "end_time": "2021-05-12T05:41:01.511052",
     "exception": false,
     "start_time": "2021-05-12T05:41:01.410848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=600, gpus=1 if torch.cuda.is_available() else 0, accumulate_grad_batches=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T05:41:01.569751Z",
     "iopub.status.busy": "2021-05-12T05:41:01.569230Z",
     "iopub.status.idle": "2021-05-12T13:02:06.697914Z",
     "shell.execute_reply": "2021-05-12T13:02:06.698424Z"
    },
    "papermill": {
     "duration": 26465.164828,
     "end_time": "2021-05-12T13:02:06.698628",
     "exception": false,
     "start_time": "2021-05-12T05:41:01.533800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42a2f5cf39d48c385105398a2096934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T13:02:06.795159Z",
     "iopub.status.busy": "2021-05-12T13:02:06.750611Z",
     "iopub.status.idle": "2021-05-12T13:02:08.948957Z",
     "shell.execute_reply": "2021-05-12T13:02:08.949777Z"
    },
    "papermill": {
     "duration": 2.226897,
     "end_time": "2021-05-12T13:02:08.950022",
     "exception": false,
     "start_time": "2021-05-12T13:02:06.723125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"MicroGAN_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040859,
     "end_time": "2021-05-12T13:02:09.052123",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.011264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## For resuming the training \n",
    "Add the saved checkpoint to the highcarbon-micrographs directory and then resume training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031489,
     "end_time": "2021-05-12T13:02:09.132971",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.101482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "new_gan = MicrographBigGAN.load_from_checkpoint(checkpoint_path=\"../input/microstrcuture-biggan-gpu/MicroGAN_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022949,
     "end_time": "2021-05-12T13:02:09.180732",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.157783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "torch.save(new_gan.generator.state_dict(), 'BigGAN-deep.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023118,
     "end_time": "2021-05-12T13:02:09.227021",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.203903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "trainer = Trainer(resume_from_checkpoint='../input/highcarbon-micrographs/MicroGAN_checkpoint.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023173,
     "end_time": "2021-05-12T13:02:09.274088",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.250915",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "trainer.fit(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-12T13:02:09.325209Z",
     "iopub.status.busy": "2021-05-12T13:02:09.324445Z",
     "iopub.status.idle": "2021-05-12T13:02:09.593620Z",
     "shell.execute_reply": "2021-05-12T13:02:09.594400Z"
    },
    "papermill": {
     "duration": 0.297594,
     "end_time": "2021-05-12T13:02:09.594673",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.297079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(gan.generator.state_dict(), 'BigGAN-deep.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040898,
     "end_time": "2021-05-12T13:02:09.695758",
     "exception": false,
     "start_time": "2021-05-12T13:02:09.654860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26490.991864,
   "end_time": "2021-05-12T13:02:12.461219",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-12T05:40:41.469355",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03955165e0e645319087ded469df198a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0a89a9c11093488180b029036a173df3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "207fc2d55d314763a543f4084c038f13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0a89a9c11093488180b029036a173df3",
       "placeholder": "​",
       "style": "IPY_MODEL_91beed9008f34128ad4e23f0842758c7",
       "value": " 50/50 [00:43&lt;00:00,  1.14it/s, loss=5.77, v_num=0, d_loss=5.690, g_loss=6.650]"
      }
     },
     "33fc35e21b5c4bacb6fbc4ab0aff8ce1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "4cc96cb6859640239a3f434bf7cc5402": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "885f59260c8d4342a6c103b02963fa79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f7728ba242f48b2b3aadf3a833eb75a",
       "max": 50,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03955165e0e645319087ded469df198a",
       "value": 50
      }
     },
     "8f7728ba242f48b2b3aadf3a833eb75a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91beed9008f34128ad4e23f0842758c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b42a2f5cf39d48c385105398a2096934": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c296a4a6337e482591115a2cae9bcab9",
        "IPY_MODEL_885f59260c8d4342a6c103b02963fa79",
        "IPY_MODEL_207fc2d55d314763a543f4084c038f13"
       ],
       "layout": "IPY_MODEL_33fc35e21b5c4bacb6fbc4ab0aff8ce1"
      }
     },
     "c296a4a6337e482591115a2cae9bcab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c36574edba584e488690901249d15ddc",
       "placeholder": "​",
       "style": "IPY_MODEL_4cc96cb6859640239a3f434bf7cc5402",
       "value": "Epoch 599: 100%"
      }
     },
     "c36574edba584e488690901249d15ddc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
